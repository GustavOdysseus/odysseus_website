from crewai import Agent, Task, Crew, Process
from typing import List, Dict
import PyPDF2
import re
import json
import spacy
from pathlib import Path
from dotenv import load_dotenv
import os
import time
import openai
from collections import defaultdict

# Carrega vari√°veis de ambiente
load_dotenv()

# Configura√ß√£o OpenAI
openai.api_key = os.getenv("OPENAI_API_KEY")
client = openai.OpenAI()

class PDFExtractorAgent(Agent):
    def __init__(self):
        super().__init__(
            role='PDF Extractor',
            goal='Extrair quest√µes de PDFs de concursos',
            backstory='Especialista em extra√ß√£o de texto de documentos PDF',
            verbose=True
        )

    def execute_task(self, task):
        pdf_paths = task.context[0].get('pdf_paths', [])
        print(f"\n=== Extraindo quest√µes de {len(pdf_paths)} PDFs ===")
        
        extracted_questions = []
        for pdf_path in pdf_paths:
            try:
                questions = self.extract_questions(pdf_path)
                extracted_questions.append(questions)
                print(f"Extra√≠das {len(questions.get('questions', []))} quest√µes de {os.path.basename(pdf_path)}")
            except Exception as e:
                print(f"Erro ao extrair quest√µes de {pdf_path}: {e}")
        
        return extracted_questions

    def extract_questions(self, pdf_path: str) -> Dict:
        """
        Extrai perguntas de um arquivo PDF e retorna um dicion√°rio com metadados.
        """
        print(f"\n=== Extraindo quest√µes de {os.path.basename(pdf_path)} ===")
        try:
            text = self.read_pdf(pdf_path)
            print(f"Texto extra√≠do com sucesso: {len(text)} caracteres")
            
            questions = self.split_into_questions(text)
            print(f"Quest√µes encontradas: {len(questions)}")
            for i, q in enumerate(questions, 1):
                print(f"  {i}. Quest√£o {q['number']} - {len(q['text'])} caracteres")
            
            result = {
                "file": pdf_path,
                "total_questions": len(questions),
                "questions": questions
            }
            print(f"Extra√ß√£o conclu√≠da: {len(questions)} quest√µes extra√≠das")
            return result
        except Exception as e:
            print(f"Erro cr√≠tico na extra√ß√£o de quest√µes do PDF {pdf_path}: {e}")
            return {
                "file": pdf_path,
                "total_questions": 0,
                "questions": [],
                "error": str(e)
            }

    def read_pdf(self, pdf_path: str) -> str:
        """
        L√™ e extrai texto de um arquivo PDF, p√°gina por p√°gina, preservando quebras e organiza√ß√£o.
        """
        print(f"\n=== Lendo PDF: {os.path.basename(pdf_path)} ===")
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"Arquivo PDF n√£o encontrado: {pdf_path}")
        
        try:
            with open(pdf_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                print(f"Total de p√°ginas: {len(reader.pages)}")
                
                if len(reader.pages) == 0:
                    print(f"Aviso: Nenhuma p√°gina encontrada no arquivo {pdf_path}")
                    return ""
                
                text = ""
                for page_num, page in enumerate(reader.pages, 1):
                    try:
                        extracted_text = page.extract_text()
                        normalized_text = self.normalize_text(extracted_text)
                        text += normalized_text + "\n"
                        print(f"P√°gina {page_num}: {len(normalized_text)} caracteres extra√≠dos")
                    except Exception as page_error:
                        print(f"Erro ao processar p√°gina {page_num} do PDF {pdf_path}: {page_error}")
                
                print(f"Leitura conclu√≠da: {len(text)} caracteres totais")
                return text
        except Exception as e:
            print(f"Erro cr√≠tico ao processar PDF {pdf_path}: {e}")
            return ""

    def split_into_questions(self, text: str) -> List[Dict]:
        """
        Divide o texto extra√≠do em quest√µes com m√∫ltiplas estrat√©gias de extra√ß√£o.
        """
        print("\n=== Dividindo texto em quest√µes ===")
        question_patterns = [
            r'(\d+\.\s*)',  # Quest√µes numeradas com ponto
            r'(\d+\)\s*)',  # Quest√µes numeradas com par√™nteses
            r'(Quest√£o\s+\d+:)',  # Padr√£o "Quest√£o X:"
        ]
        
        questions = []
        print("Tentando diferentes padr√µes de extra√ß√£o:")
        
        for pattern in question_patterns:
            print(f"Testando padr√£o: {pattern}")
            question_blocks = re.split(pattern, text)
            
            if len(question_blocks) > 2:
                print(f"Padr√£o encontrou {(len(question_blocks)-1)//2} poss√≠veis quest√µes")
                for i in range(1, len(question_blocks), 2):
                    try:
                        question_number = question_blocks[i].strip()
                        question_text = question_blocks[i + 1].strip()
                        
                        if 10 < len(question_text) < 1000:
                            questions.append({
                                "number": question_number,
                                "text": question_text,
                                "raw_text": f"{question_number} {question_text}",
                                "length": len(question_text)
                            })
                            print(f"  Quest√£o {question_number} extra√≠da: {len(question_text)} caracteres")
                    except Exception as e:
                        print(f"Erro ao processar quest√£o: {e}")
            
            if questions:
                print(f"Padr√£o {pattern} encontrou {len(questions)} quest√µes v√°lidas")
                break
            else:
                print(f"Padr√£o {pattern} n√£o encontrou quest√µes v√°lidas")
        
        print(f"\nTotal de quest√µes extra√≠das: {len(questions)}")
        return questions

    def normalize_text(self, text: str) -> str:
        """
        Limpa e normaliza o texto extra√≠do para melhorar a consist√™ncia.
        """
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'‚Ä¶', '...', text)
        return text.strip()

    def extract_structure(self, text: str) -> Dict:
        """
        Adiciona marcadores ao texto para separar t√≠tulos, subt√≠tulos, tabelas, etc.
        """
        structured_text = re.sub(r'^\s*[A-Z ]+\s*$', r'<T√çTULO>\g<0>', text, flags=re.MULTILINE)
        structured_text = re.sub(r'(\d+\))', r'<QUEST√ÉO>\g<1>', structured_text)
        return {"structured_text": structured_text}


class QuestionAnalyzerAgent(Agent):
    def __init__(self):
        super().__init__(
            role='Question Analyzer',
            goal='Analisar padr√µes espec√≠ficos de portugu√™s',
            backstory='Especialista em an√°lise de conte√∫do e identifica√ß√£o de padr√µes em quest√µes de concurso',
            verbose=True
        )

    def execute_task(self, task):
        questions_list = task.context[0].get('extracted_questions', [])
        
        # Achatar a lista de quest√µes
        all_questions = []
        for questions_dict in questions_list:
            if isinstance(questions_dict, dict) and 'questions' in questions_dict:
                all_questions.extend(questions_dict['questions'])
        
        analysis = self.analyze_questions(all_questions)
        
        result = "AN√ÅLISE DETALHADA DE PORTUGU√äS\n\n"
        
        result += "üìö T√ìPICOS GERAIS:\n"
        for topic, count in analysis['t√≥picos_gerais'].items():
            result += f"- {topic}: {count} quest√µes\n"
        
        result += "\nüî§ T√ìPICOS GRAMATICAIS:\n"
        for topic, count in analysis['t√≥picos_gram√°tica'].items():
            result += f"- {topic}: {count} quest√µes\n"
        
        result += "\n‚úçÔ∏è ACENTUA√á√ÉO:\n"
        for accent, count in analysis['acentua√ß√£o'].items():
            result += f"- {accent}: {count} ocorr√™ncias\n"
        
        result += "\nüìù PONTUA√á√ÉO:\n"
        for punct, count in analysis['pontua√ß√£o'].items():
            result += f"- {punct}: {count} ocorr√™ncias\n"
        
        result += "\n‚è∞ TEMPOS VERBAIS:\n"
        for tense, count in analysis['tempos_verbais'].items():
            result += f"- {tense}: {count} ocorr√™ncias\n"
        
        return result

    def analyze_questions(self, questions: List[Dict]) -> Dict:
        """
        Analisa as quest√µes para identificar padr√µes espec√≠ficos de portugu√™s.
        """
        topics = defaultdict(int)
        grammar_topics = defaultdict(int)
        punctuation = defaultdict(int)
        accentuation = defaultdict(int)
        verb_tenses = defaultdict(int)
        
        # Padr√µes espec√≠ficos de portugu√™s
        patterns = {
            'acentua√ß√£o': {
                'crase': [r'crase', r'√†\s', r'√†s\s', r'√†quele', r'√†quela'],
                'agudo': [r'[√°√©√≠√≥√∫]', r'acento agudo'],
                'circunflexo': [r'[√¢√™√Æ√¥√ª]', r'acento circunflexo'],
                'til': [r'[√£√µ]', r'til']
            },
            'pontua√ß√£o': {
                'v√≠rgula': [r'v√≠rgula', r',\s'],
                'ponto_v√≠rgula': [r'ponto e v√≠rgula', r';\s'],
                'dois_pontos': [r'dois pontos', r':\s'],
                'travess√£o': [r'travess√£o', r'‚Äî'],
            },
            'verbos': {
                'presente': [r'presente do indicativo', r'presente simples'],
                'pret√©rito_perfeito': [r'pret√©rito perfeito', r'passado perfeito'],
                'pret√©rito_imperfeito': [r'pret√©rito imperfeito', r'passado imperfeito'],
                'futuro': [r'futuro do presente', r'futuro simples'],
                'subjuntivo': [r'subjuntivo', r'modo subjuntivo']
            },
            'gram√°tica': {
                'concord√¢ncia_verbal': [r'concord√¢ncia verbal', r'sujeito concorda'],
                'concord√¢ncia_nominal': [r'concord√¢ncia nominal', r'substantivo concorda'],
                'reg√™ncia': [r'reg√™ncia', r'verbo rege'],
                'coloca√ß√£o_pronominal': [r'coloca√ß√£o pronominal', r'pr√≥clise', r'√™nclise', r'mes√≥clise'],
                'an√°lise_sint√°tica': [r'an√°lise sint√°tica', r'ora√ß√£o subordinada', r'per√≠odo composto']
            }
        }
        
        for question in questions:
            text = question['text'].lower()
            
            # An√°lise por padr√µes espec√≠ficos
            for category, subcategories in patterns.items():
                for subcategory, patterns_list in subcategories.items():
                    for pattern in patterns_list:
                        if re.search(pattern, text, re.IGNORECASE):
                            if category == 'acentua√ß√£o':
                                accentuation[subcategory] += 1
                            elif category == 'pontua√ß√£o':
                                punctuation[subcategory] += 1
                            elif category == 'verbos':
                                verb_tenses[subcategory] += 1
                            elif category == 'gram√°tica':
                                grammar_topics[subcategory] += 1
            
            # Identifica√ß√£o de t√≥picos gerais
            if "interpreta√ß√£o" in text or "compreens√£o" in text:
                topics["Interpreta√ß√£o de Texto"] += 1
            if "literatura" in text:
                topics["Literatura"] += 1
            if "fon√©tica" in text or "fonologia" in text:
                topics["Fon√©tica/Fonologia"] += 1
            if "morfologia" in text:
                topics["Morfologia"] += 1
            if "sintaxe" in text:
                topics["Sintaxe"] += 1
            if "sem√¢ntica" in text:
                topics["Sem√¢ntica"] += 1
            if "ortografia" in text:
                topics["Ortografia"] += 1

        return {
            "t√≥picos_gerais": dict(sorted(topics.items(), key=lambda x: x[1], reverse=True)),
            "t√≥picos_gram√°tica": dict(sorted(grammar_topics.items(), key=lambda x: x[1], reverse=True)),
            "acentua√ß√£o": dict(sorted(accentuation.items(), key=lambda x: x[1], reverse=True)),
            "pontua√ß√£o": dict(sorted(punctuation.items(), key=lambda x: x[1], reverse=True)),
            "tempos_verbais": dict(sorted(verb_tenses.items(), key=lambda x: x[1], reverse=True))
        }

class PatternDiscoveryAgent(Agent):
    def __init__(self):
        super().__init__(
            role='Pattern Discoverer',
            goal='Descobrir tend√™ncias e padr√µes nas quest√µes',
            backstory='Especialista em an√°lise de tend√™ncias e identifica√ß√£o de padr√µes em concursos',
            verbose=True
        )

    def execute_task(self, task):
        analysis_results = task.context[0].get('analysis_results', '')
        
        insights = []
        
        # Extrair informa√ß√µes do resultado da an√°lise
        sections = analysis_results.split('\n\n')
        
        for section in sections:
            if "T√ìPICOS GERAIS" in section:
                topics = [line.strip('- ').split(':')[0] for line in section.split('\n')[1:] if line]
                if topics:
                    insights.append(f"üîç FOCO DO CONCURSO: O concurso tem √™nfase especial em {', '.join(topics[:3])}")
            
            if "TIPOS DE QUEST√ÉO" in section:
                types = [line.strip('- ').split(':')[0] for line in section.split('\n')[1:] if line]
                if types:
                    insights.append(f"üìã ESTILO DE PROVA: Predominam quest√µes do tipo {', '.join(types[:2])}")
        
        # Gerar recomenda√ß√µes pr√°ticas
        insights.append("\nüí° RECOMENDA√á√ïES PARA ESTUDO:")
        insights.append("1. Focar nos t√≥picos mais frequentes identificados")
        insights.append("2. Praticar especialmente os tipos de quest√£o predominantes")
        insights.append("3. Revisar os subt√≥picos espec√≠ficos que mais aparecem")
        
        return "\n".join(insights)

class ReportGeneratorAgent(Agent):
    def __init__(self):
        super().__init__(
            role='Report Generator',
            goal='Gerar relat√≥rio final com insights pr√°ticos',
            backstory='Especialista em comunica√ß√£o e s√≠ntese de informa√ß√µes',
            verbose=True
        )

    def execute_task(self, task):
        patterns = task.context[0].get('patterns', '')
        
        report = """
üìä AN√ÅLISE DE TEND√äNCIAS DO CONCURSO
===================================

"""
        # Adicionar padr√µes descobertos
        report += patterns

        # Adicionar conclus√£o
        report += """

üéØ CONCLUS√ÉO
-----------
Esta an√°lise revela os padr√µes mais importantes e frequentes nas quest√µes do concurso,
permitindo um direcionamento mais eficiente dos estudos e da prepara√ß√£o.

"""
        return report

def analyze_exam_pdfs(pdf_paths: List[str], subject: str = "Portugu√™s"):
    """
    Analisa PDFs de provas e gera um relat√≥rio completo.
    """
    print("\n=== Iniciando an√°lise de PDFs ===")
    print(f"N√∫mero de arquivos a serem analisados: {len(pdf_paths)}")
    for pdf in pdf_paths:
        print(f"- {os.path.basename(pdf)}")

    # Criar agentes
    print("\n=== Inicializando agentes ===")
    extractor = PDFExtractorAgent()
    analyzer = QuestionAnalyzerAgent()
    pattern_discoverer = PatternDiscoveryAgent()
    report_generator = ReportGeneratorAgent()
    print("Agentes inicializados com sucesso")

    # Criar tarefas
    print("\n=== Definindo tarefas ===")
    tasks = [
        Task(
            description=f"Extrair quest√µes de {len(pdf_paths)} PDFs",
            agent=extractor,
            context=[{
                "description": f"Extrair quest√µes de {len(pdf_paths)} PDFs",
                "pdf_paths": pdf_paths,
                "expected_output": "Lista de quest√µes extra√≠das"
            }],
            expected_output="Lista de quest√µes extra√≠das"
        ),
        Task(
            description="Analisar cada quest√£o extra√≠da",
            agent=analyzer,
            context=[{
                "description": "Analisar cada quest√£o extra√≠da",
                "extracted_questions": [],
                "expected_output": "An√°lise detalhada das quest√µes"
            }],
            expected_output="An√°lise detalhada das quest√µes"
        ),
        Task(
            description="Descobrir padr√µes entre as quest√µes",
            agent=pattern_discoverer,
            context=[{
                "description": "Descobrir padr√µes entre as quest√µes",
                "analysis_results": "",
                "expected_output": "Relat√≥rio de padr√µes encontrados"
            }],
            expected_output="Relat√≥rio de padr√µes encontrados"
        ),
        Task(
            description="Gerar relat√≥rio final",
            agent=report_generator,
            context=[{
                "description": "Gerar relat√≥rio final",
                "patterns": "",
                "expected_output": "Relat√≥rio completo de an√°lise"
            }],
            expected_output="Relat√≥rio completo de an√°lise"
        )
    ]
    print("Tarefas definidas com sucesso")

    # Criar crew
    print("\n=== Configurando equipe de an√°lise ===")
    crew = Crew(
        agents=[extractor, analyzer, pattern_discoverer, report_generator],
        tasks=tasks,
        verbose=True
    )
    print("Equipe configurada com sucesso")

    # Executar an√°lise
    print("\n=== Iniciando execu√ß√£o da an√°lise ===")
    result = crew.kickoff()
    print("\n=== An√°lise conclu√≠da ===")
    
    # Converter resultado para string e formatar
    print("\n=== Gerando relat√≥rio final ===")
    result_str = f"""
An√°lise de Quest√µes de Concurso
==============================

Arquivos analisados:
{', '.join(os.path.basename(pdf) for pdf in pdf_paths)}

Resultado da An√°lise:
-------------------
{str(result)}
"""
    
    # Salvar resultado
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(os.path.dirname(__file__), f"analise_comparativa_{timestamp}.txt")
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(result_str)
        print(f"\nAn√°lise salva com sucesso em: {output_file}")
    except Exception as e:
        print(f"Erro ao salvar arquivo: {e}")
    
    return result

if __name__ == "__main__":
    pdf_dir = "/Users/gustavomonteiro/Desktop/prova/"
    pdf_files = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.endswith('.pdf')]
    result = analyze_exam_pdfs(pdf_files)