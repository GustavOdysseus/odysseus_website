{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplos de Integração com AgentOps\n",
    "\n",
    "Este notebook demonstra exemplos práticos de integração do AgentOps com diferentes frameworks de IA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração Inicial\n",
    "\n",
    "Primeiro, vamos instalar as dependências necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install agentops crewai langchain autogen llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Integração com CrewAI\n",
    "\n",
    "Exemplo de uso do AgentOps com CrewAI para monitorar uma equipe de agentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from agentops import Client\n",
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "# Configuração do AgentOps\n",
    "client = Client()\n",
    "client.configure(api_key=\"sua_api_key\")\n",
    "client.start_session(tags=[\"crewai\", \"exemplo\"])\n",
    "\n",
    "# Criação dos agentes\n",
    "pesquisador = Agent(\n",
    "    role=\"Pesquisador\",\n",
    "    goal=\"Coletar informações relevantes\",\n",
    "    backstory=\"Especialista em pesquisa de dados\",\n",
    "    allow_delegation=False\n",
    ")\n",
    "\n",
    "analista = Agent(\n",
    "    role=\"Analista\",\n",
    "    goal=\"Analisar dados coletados\",\n",
    "    backstory=\"Especialista em análise de dados\",\n",
    "    allow_delegation=False\n",
    ")\n",
    "\n",
    "# Criação das tarefas\n",
    "tarefa_pesquisa = Task(\n",
    "    description=\"Coletar dados sobre mercado de IA\",\n",
    "    agent=pesquisador\n",
    ")\n",
    "\n",
    "tarefa_analise = Task(\n",
    "    description=\"Analisar tendências nos dados\",\n",
    "    agent=analista\n",
    ")\n",
    "\n",
    "# Criação e execução da crew\n",
    "crew = Crew(\n",
    "    agents=[pesquisador, analista],\n",
    "    tasks=[tarefa_pesquisa, tarefa_analise],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "resultado = crew.kickoff()\n",
    "\n",
    "# Finalização da sessão\n",
    "client.end_session(\n",
    "    end_state=\"Success\",\n",
    "    end_state_reason=\"Análise completa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integração com LangChain\n",
    "\n",
    "Exemplo de uso do AgentOps com LangChain para monitorar agentes e ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from agentops import Client\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Configuração do AgentOps\n",
    "client = Client()\n",
    "client.configure(api_key=\"sua_api_key\")\n",
    "client.start_session(tags=[\"langchain\", \"exemplo\"])\n",
    "\n",
    "# Configuração do LangChain\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"python_repl\", \"terminal\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Execução de tarefas\n",
    "result = agent.run(\"Crie um gráfico de barras usando matplotlib com os dados [1,2,3,4,5]\")\n",
    "\n",
    "# Finalização da sessão\n",
    "client.end_session(\n",
    "    end_state=\"Success\",\n",
    "    end_state_reason=\"Gráfico criado\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Integração com AutoGen\n",
    "\n",
    "Exemplo de uso do AgentOps com AutoGen para monitorar conversas entre agentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from agentops import Client\n",
    "import autogen\n",
    "\n",
    "# Configuração do AgentOps\n",
    "client = Client()\n",
    "client.configure(api_key=\"sua_api_key\")\n",
    "client.start_session(tags=[\"autogen\", \"exemplo\"])\n",
    "\n",
    "# Configuração do AutoGen\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": \"sua_openai_key\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Criação dos agentes\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config={\"config_list\": config_list}\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config={\"config_list\": config_list}\n",
    ")\n",
    "\n",
    "# Iniciando conversa\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"Como podemos otimizar um algoritmo de busca binária?\"\n",
    ")\n",
    "\n",
    "# Finalização da sessão\n",
    "client.end_session(\n",
    "    end_state=\"Success\",\n",
    "    end_state_reason=\"Conversa completa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Integração com LlamaIndex\n",
    "\n",
    "Exemplo de uso do AgentOps com LlamaIndex para monitorar processamento de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from agentops import Client\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "# Configuração do AgentOps\n",
    "client = Client()\n",
    "client.configure(api_key=\"sua_api_key\")\n",
    "client.start_session(tags=[\"llamaindex\", \"exemplo\"])\n",
    "\n",
    "# Carregamento e indexação de documentos\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# Consulta ao índice\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Qual é o tema principal dos documentos?\")\n",
    "\n",
    "# Finalização da sessão\n",
    "client.end_session(\n",
    "    end_state=\"Success\",\n",
    "    end_state_reason=\"Consulta realizada\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análise dos Resultados\n",
    "\n",
    "Após executar os exemplos acima, você pode acessar o dashboard do AgentOps para visualizar:\n",
    "\n",
    "1. Métricas de performance de cada framework\n",
    "2. Logs detalhados das interações\n",
    "3. Custos associados às chamadas LLM\n",
    "4. Tempos de resposta e latência\n",
    "5. Padrões de uso e comportamento dos agentes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
